{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c61f87a-15d4-4f1f-b019-b6c373e237a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ab107-6a14-478e-ad45-133cd20ff430",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b01588-eb8b-44e7-b3e6-604310d9fad0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output_image_size(input_size, filter_size, stride=1, pad=0):\n",
    "  in_h, in_w = input_size\n",
    "  filter_h, filter_w = filter_size\n",
    "  \n",
    "  out_h = (in_h - filter_h + 2 * pad) / stride + 1\n",
    "  assert out_h == round(out_h)\n",
    "  out_w = (in_w - filter_w + 2 * pad) / stride + 1\n",
    "  assert out_w == round(out_w)\n",
    "  \n",
    "  return int(out_h), int(out_w)\n",
    "\n",
    "\n",
    "def filter_size(input_size, output_size, stride=1, pad=0):\n",
    "  in_h, in_w = input_size\n",
    "  out_h, out_w = output_size\n",
    "  \n",
    "  filter_h = (in_h + 2 * pad) - stride * (out_h - 1)\n",
    "  filter_w = (in_w + 2 * pad) - stride * (out_w - 1)\n",
    "  \n",
    "  return int(filter_h), int(filter_w)\n",
    "\n",
    "\n",
    "def im2col_naive(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "  in_h, in_w = input_data.shape\n",
    "  out_h, out_w = output_image_size((in_h, in_w), (filter_h, filter_w), stride, pad)\n",
    "  \n",
    "  col = np.zeros((filter_h, filter_w, out_h, out_w))\n",
    "  for i in range(filter_h):\n",
    "    for j in range(filter_w):\n",
    "      col[i, j, :, :] = input_data[i:i+out_h, j:j+out_w]\n",
    "      \n",
    "  col = col.reshape(filter_h * filter_w, out_h * out_w)\n",
    "  \n",
    "  return col\n",
    "  \n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "  N, C, H, W = input_data.shape\n",
    "  out_h, out_w = output_image_size((H, W), (filter_h, filter_w), stride, pad)\n",
    "  \n",
    "  img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "  col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "  \n",
    "  for i in range(filter_h):\n",
    "    i_max = i + stride*out_h\n",
    "    for j in range(filter_w):\n",
    "      j_max = j + stride*out_w\n",
    "      col[:, :, i, j, :, :] = img[:, :, i:i_max:stride, j:j_max:stride]\n",
    "  \n",
    "  col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "  return col\n",
    "\n",
    "\n",
    "def col2im_naive(col, input_shape, output_shape, stride=1, pad=0):\n",
    "  # col: (out_h * out_w) x (filter_h * filter_w)\n",
    "  # filter: (filter_h * filter_w) * ( FN )\n",
    "  in_h, in_w = input_shape\n",
    "  out_h, out_w = output_shape\n",
    "  \n",
    "  filter_h, filter_w = filter_size((in_h, in_w), (out_h, out_w), stride, pad)\n",
    "  \n",
    "  col = col.reshape(out_h, out_w, filter_h, filter_w)\n",
    "  \n",
    "  image = np.zeros((in_h, in_w))\n",
    "  \n",
    "  for i in range(filter_h):\n",
    "    i_max = i + out_h\n",
    "    for j in range(filter_w):\n",
    "      j_max = j + out_w\n",
    "      image[i:i_max, j:j_max] += col[:, :, i, j]\n",
    "      \n",
    "  return image\n",
    "\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "  # col: (N * out_h * out_w) x (C * filter_h * filter_w)\n",
    "  N, C, H, W = input_shape\n",
    "  \n",
    "  out_h, out_w = output_image_size((H, W), (filter_h, filter_w), stride=1, pad=0)\n",
    "  \n",
    "  col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "  image = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "  \n",
    "  for i in range(filter_h):\n",
    "    i_max = i + stride * out_h\n",
    "    for j in range(filter_w):\n",
    "      j_max = j + stride * out_w\n",
    "      image[:, :, i:i_max:stride, j:j_max:stride] += col[:, :, i, j, :, :]\n",
    "      \n",
    "  return image[:, :, pad:H+pad, pad:W+pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014e3c3-9ddb-4871-be62-2defbc12866f",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38f972d-0a8b-423c-b8a1-92d5d74e56e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions.py\n",
    "\n",
    "def identity_function(x):\n",
    "  return x\n",
    "\n",
    "\n",
    "def step_function(x):\n",
    "  return (x > 0).astype(np.int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "  return sigmoid(x) * sigmoid(1 - x)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "  return step_function(x)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "  ma = np.max(x, axis=-1, keepdims=True)\n",
    "  a = np.exp(x - ma)\n",
    "  return a / np.sum(a, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "def sum_squared_error(y, t):\n",
    "  return np.sum((y - t)**2) * 0.5\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "  if y.ndim == 1:\n",
    "    t = t.reshape((1, t.size))\n",
    "    y = y.reshape((1, y.size))\n",
    "  \n",
    "  if y.size == t.size:\n",
    "    t = t.argmax(axis=1)\n",
    "    \n",
    "  batch_size = y.shape[0]\n",
    "  return -np.sum(np.log(y[:, t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "def softmax_loss(X, t):\n",
    "  y = softmax(X)\n",
    "  return cross_entropy_error(y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa537b-9aab-478c-9098-2c83a4e5489f",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819c2782-1142-466c-a3b2-2efb4e7e686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.py\n",
    "# https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/common/layers.py\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  def forward(self, x):\n",
    "    pass\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "  def __init__(self):\n",
    "    self.out = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = sigmoid(x)\n",
    "    self.out = out\n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    dx = dout * self.out * (1 - self.out)\n",
    "    return dx\n",
    "  \n",
    "  \n",
    "class Relu(Layer):\n",
    "  def __init__(self):\n",
    "    self.mask = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    self.mask = x < 0\n",
    "    out = np.maximum(x, 0)\n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    dout[self.mask] = 0\n",
    "    dx = dout\n",
    "    return dx\n",
    "  \n",
    "  \n",
    "class Affine(Layer):\n",
    "  def __init__(self, W, b):\n",
    "    self.W = W\n",
    "    self.b = b\n",
    "    \n",
    "    self.x = None\n",
    "    self.original_x_shape = None\n",
    "    \n",
    "    self.dW = None\n",
    "    self.db = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    self.original_x_shape = x.shape  # テンソル対応?\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    self.x = x\n",
    "    \n",
    "    out = self.x @ self.W + self.b\n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    dx = dout @ self.W.T\n",
    "    self.dW = self.x.T @ dout\n",
    "    self.db = np.sum(dout, axis=0)\n",
    "    \n",
    "    dx = dx.reshape(*self.original_x_shape)\n",
    "    return dx\n",
    "  \n",
    "\n",
    "class SoftmaxWithLoss(Layer):\n",
    "  def __init__(self):\n",
    "    self.loss = None\n",
    "    self.y = None\n",
    "    self.t = None\n",
    "    \n",
    "  def forward(self, x, t):\n",
    "    self.t = t\n",
    "    self.y = softmax(x)\n",
    "    self.loss = cross_entropy_error(self.y, self.t)\n",
    "    return self.loss\n",
    "  \n",
    "  def backward(self, dout=1):\n",
    "    batch_size = self.t.shape[0]\n",
    "    if self.t.size == self.y.size:\n",
    "      dx = (self.y - self.t) / batch_size\n",
    "    else:\n",
    "      dx = self.y.copy()\n",
    "      dx[:, t] -= 1\n",
    "      dx /= batch_size\n",
    "    \n",
    "    return dx\n",
    "\n",
    "  \n",
    "class Dropout(Layer):\n",
    "  def __init__(self, dropout_ratio=0.5):\n",
    "    super.__init__()\n",
    "    self.dropout_ratio = dropout_ratio\n",
    "    self.mask = None\n",
    "    \n",
    "  def forward(self, x, train_flag=True):\n",
    "    if train_flag:\n",
    "      self.mask = np.random.rand(*x.shape) > dropout_ratio\n",
    "      return x * self.mask\n",
    "    else:\n",
    "      return x * (1 - self.dropout_ratio)\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    return dout * self.mask\n",
    "  \n",
    "\n",
    "class BatchNormalization:\n",
    "  def __init__(self, gamma, beta):\n",
    "    self.params = [gamma, beta]\n",
    "    self.grads = [np.zeros_like(gamma), np.zeros_like(beta)]\n",
    "    self.cache = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    N, D = x.shape\n",
    "    gamma, beta = self.params\n",
    "    \n",
    "    mu = np.mean(x, axis=0)\n",
    "    xc = x - mu\n",
    "    var = np.mean(xc**2, axis=0)\n",
    "    std = np.sqrt(var + 1e-7)\n",
    "    xn = xc / std\n",
    "    \n",
    "    out = gamma * xn + beta\n",
    "    \n",
    "    self.cache = (xc, std, xn)\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    N, D = dout.shape\n",
    "    gamma, beta = self.params\n",
    "    xc, std, xn = self.cache\n",
    "    \n",
    "    dbeta = np.sum(dz, axis=0)\n",
    "    dgamma = np.sum(dz * xn, axis=0)\n",
    "    dxn = dout * gamma\n",
    "    dxc = dxn / std\n",
    "    dstd = -np.sum(dxn * xc, axis=0) / std**2\n",
    "    dvar = 0.5 * dstd / std\n",
    "    dxc += 2 * dvar * xc / N\n",
    "    dmu = np.sum(-dxc, axis=0)\n",
    "    dx = dxc + dmu / N\n",
    "    \n",
    "    self.grads[0][...] = dgamma\n",
    "    self.grads[1][...] = dbeta\n",
    "    \n",
    "    return dx\n",
    "  \n",
    "\n",
    "class Convolution:\n",
    "  def __init__(self, W, b, stride=1, pad=0):\n",
    "    self.params = [W, b]\n",
    "    self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "    self.stride = stride\n",
    "    self.pad = pad\n",
    "    self.cache = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    N, C, H, W = x.shape\n",
    "    W, b = self.params\n",
    "    FN, C, FH, FW = W.shape\n",
    "    \n",
    "    OH, OW = output_image_size((H, W), (FH, FW), self.stride, self.pad)\n",
    "    \n",
    "    col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "    col_W = W.reshape(FN, -1).T\n",
    "    out = col @ col_W + b\n",
    "    out = out.reshape(N, OH, OW, -1).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    self.cache = (x, col, col_W)\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    W, b = self.params\n",
    "    FN, C, FH, FW = W.shape\n",
    "    x, col, col_W = self.cache\n",
    "    \n",
    "    dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)\n",
    "    \n",
    "    db = np.sum(dout, axis=0)\n",
    "    dW = col.T @ dout\n",
    "    dW = dW.T.reshape(FN, C, FH, FW)\n",
    "    dcol = dout @ col_W.T\n",
    "    \n",
    "    dx = col2im(col, x.shape, FH, FW, self.stride, self.pad)\n",
    "    return dx\n",
    "  \n",
    "  \n",
    "class Pooling:\n",
    "  def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "    self.pool_h = pool_h\n",
    "    self.pool_w = pool_w\n",
    "    self.stride = stride\n",
    "    self.pad = pad\n",
    "    \n",
    "    self.cache = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    N, C, H, W = x.shape\n",
    "    \n",
    "    OH, OW = output_image_size((H, W), (self.pool_h, self.pool_w), self.stride, self.pad)\n",
    "    \n",
    "    col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "    col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "    \n",
    "    arg_max = np.argmax(col, axis=1)\n",
    "    out = np.max(col, axis=1)\n",
    "    out = out.reshape(N, OH, OW, C).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    self.cache = (x, arg_max)\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def backward(self, dout):\n",
    "    N, C, OH, OW = dout.shape\n",
    "    x, arg_max = self.cache\n",
    "    \n",
    "    dout  = dout.transpose(0, 2, 3, 1)\n",
    "    \n",
    "    dmax = np.zeros((dout.size, self.pool_h * self.pool_w))\n",
    "    dmax[np.arange(dout.size), arg_max.flatten()] = dout.flatten()\n",
    "    dmax = dmax.reshape(dout.shape + (self.pool_h * self.pool_w,))\n",
    "    \n",
    "    dcol = dmax.reshape(N * OH * OW, -1)\n",
    "    dx = col2im(dcol, x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6974aff-b84a-4d27-8af5-5a70947bec1a",
   "metadata": {},
   "source": [
    "## optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a919c41-8204-493a-b432-ffcc33d87333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.py\n",
    "\n",
    "class Optimizer:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  def update(self, params, grads):\n",
    "    pass\n",
    "  \n",
    "\n",
    "class SGD(Optimizer):\n",
    "  def __init__(self, lr=0.01):\n",
    "    super.__init__()\n",
    "    self.lr = lr\n",
    "    \n",
    "  def update(self, params, grads):\n",
    "    for key in params.keys():\n",
    "      params[key] = params[key] - self.lr * grads[key]\n",
    "      \n",
    "\n",
    "class Momentum(Optimizer):\n",
    "  def __init__(self, lr=0.01, momentum=0.9):\n",
    "    super.__init__()\n",
    "    self.lr = lr\n",
    "    self.momentum = momentum\n",
    "    self.v = None\n",
    "    \n",
    "  def update(self, params, grads):\n",
    "    if self.v is None:\n",
    "      self.v = {}\n",
    "      for key, val in  params.items():\n",
    "        self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "    for key in params.keys():\n",
    "      self.v[key] = self.momentum * self.v - self.lr * grads[key]\n",
    "      params[key] += self.v\n",
    "      \n",
    "      \n",
    "class AdaGrad(Optimizer):\n",
    "  def __init__(self, lr=0.01):\n",
    "    super.__init__()\n",
    "    self.lr = lr\n",
    "    self.h = None\n",
    "    \n",
    "  def update(self, params, grads):\n",
    "    if h is None:\n",
    "      self.h = {}\n",
    "      for key, val in params.items():\n",
    "        self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "    for key in params.keys():\n",
    "      self.h[key] += grads[key]**2\n",
    "      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "      \n",
    "      \n",
    "class RMSProp(Optimizer):\n",
    "  def __init__(self, lr=0.01, decay_rate=0.99):\n",
    "    super.__init()\n",
    "    self.lr = lr\n",
    "    self.decay_rate = decay_rate\n",
    "    self.h = None\n",
    "    \n",
    "  def update(self, params, grads):\n",
    "    if h is None:\n",
    "      self.h = {}\n",
    "      for key, val in params.items():\n",
    "        self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "    for key in params.keys():\n",
    "      self.h[key] = self.decay_rate * self.h[key] + (1 - self.decay_rate) * grads[key]**2\n",
    "      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)    \n",
    "      \n",
    "      \n",
    "class Adam(Optimizer):\n",
    "  def __init__(self, lr=0.001, beta1=0.99, beta2=0.999):\n",
    "    super.__init__()\n",
    "    self.lr = lr\n",
    "    self.beta1 = beta1\n",
    "    self.beta2 = beta2\n",
    "    self.iter = 0\n",
    "    self.v = None\n",
    "    self.h = None\n",
    "    \n",
    "  def update(self, params, grads):\n",
    "    if v is None:\n",
    "      self.v = {}\n",
    "      for key, val in params.items():\n",
    "        self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "    if h is None:\n",
    "      self.h = {}\n",
    "      for key, val in params.items():\n",
    "        self.h[key] = np.zeros_like(val)\n",
    "    \n",
    "    self.iter += 1\n",
    "    lr_t = self.lr * np.sqrt(1 - self.beta2 ** self.iter) / np.sqrt(1 - self.beta1 ** self.iter)\n",
    "    \n",
    "    for key in params.keys():\n",
    "      self.v[key] = self.beta1 * self.v[key] + (1 - self.beta1) * grads[key]\n",
    "      self.h[key] = self.beta2 * self.h[key] + (1 - self.beta2) * grads[key]**2\n",
    "      params[key] -= lr_t * self.v[key] / np.sqrt(self.h[key] + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20dc86e-5e11-44ad-ad88-158317e6172a",
   "metadata": {},
   "source": [
    "## networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae8f825-1fc2-4cb6-ae35-6d07d27dabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "  \"\"\"単純なConvNet\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape=(1,28,28), \n",
    "               conv_params={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "               hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "    \n",
    "    FN = conv_params['filter_num']\n",
    "    FH = FW = conv_params['filter_size']\n",
    "    pad = conv_params['pad']\n",
    "    stride = conv_params['stride']\n",
    "    C, H, W = input_shape\n",
    "    \n",
    "    conv_output_h = (H - FH + 2 * pad) / stride + 1\n",
    "    conv_output_w = (W - FW + 2 * pad) / stride + 1\n",
    "    pooling_output_h = conv_output_h / 2\n",
    "    pooling_output_w = conv_output_w / 2\n",
    "    \n",
    "    self.params = {}\n",
    "    self.params['W1'] = weight_init_std * np.random.randn(FN, C, FH, FW)\n",
    "    self.params['b1'] = np.zeros(FN)\n",
    "    self.params['W2'] = weight_init_std * np.random.randn(FN * pooling_output_h * pooling_output_w, hidden_size)\n",
    "    self.params['b2'] = np.zeros(hidden_size)\n",
    "    self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    self.params['b3'] = np.zeros(output_size)\n",
    "    \n",
    "    self.layers = OrderedDict()\n",
    "    self.layers['Conv1'] = CNN(self.params['W1'], self.params['b1'], stride, pad)\n",
    "    self.layers['Relu1'] = Relu()\n",
    "    self.layers['Pooling1'] = Pooling(pooling_output_h, pooling_output_w, stride=2)\n",
    "    self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "    self.layers['Relu2'] = Relu()\n",
    "    self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "    \n",
    "    self.lastlayer = SoftmaxWithLoss()\n",
    "  \n",
    "  \n",
    "  def predict(self, x):\n",
    "    for layer in self.layers.values():\n",
    "      x = layer.forward(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "  \n",
    "  def loss(self, x, t):\n",
    "    x = self.predict(x)\n",
    "    return self.lastyear.forward(x, t)\n",
    "  \n",
    "  \n",
    "  def accuracy(self, x, t, batch_size=100):\n",
    "    acc = 0\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    for i in range(N // batch_size):\n",
    "      tmp_x = x[i * batch_size : (i+1) * batch_size]\n",
    "      tmp_t = t[i * batch_size : (i+1) * batch_size]\n",
    "      y = self.predict(x)\n",
    "      y = np.argmax(y, axis=1)\n",
    "      acc += np.sum(y == tmp_t)\n",
    "    \n",
    "    acc /= N\n",
    "    return acc\n",
    "  \n",
    "  \n",
    "  def gradient(self, x, t):\n",
    "    # forward\n",
    "    self.loss(x, t)\n",
    "    \n",
    "    # backward\n",
    "    dout = 1\n",
    "    dout = self.lastlayer.backward(dout)\n",
    "    \n",
    "    for layer in reversed(list(self.layers.values())):\n",
    "      dout = layer.backward(dout)\n",
    "      \n",
    "    grads = {}\n",
    "    grads['W1'] = self.layers['Conv1'].dW\n",
    "    grads['b1'] = self.layers['Conv1'].db\n",
    "    grads['W2'] = self.layers['Affine1'].dW\n",
    "    grads['b2'] = self.layers['Affine1'].db\n",
    "    grads['W3'] = self.layers['Affine2'].dW\n",
    "    grads['b3'] = self.layers['Affine2'].db\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7522e9-c60b-498c-8feb-d9b052773700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d5258d2-1ecf-4dbf-b36e-66b1ebf7511a",
   "metadata": {},
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c24375e-4803-4c81-8839-51429df8d724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# weight_init_activation_histogram.py\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(x, 0)\n",
    "\n",
    "def tanh(x):\n",
    "  return np.tanh(x)\n",
    "\n",
    "\n",
    "input_data = np.random.randn(1000, 100)\n",
    "node_num = 100\n",
    "hidden_layer_size = 5\n",
    "activations = {}\n",
    "\n",
    "x = input_data\n",
    "\n",
    "for i in range(hidden_layer_size):\n",
    "  if i != 0:\n",
    "    x = activations[i-1]\n",
    "    \n",
    "  w = np.random.randn(node_num, node_num) * 1\n",
    "  z = np.dot(x, w)\n",
    "  a = tanh(z)\n",
    "  activations[i] = a\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "for i, a in activations.items():\n",
    "  plt.subplot(1, len(activations), i+1)\n",
    "  plt.title(f\"{i+1}-layer\")\n",
    "  \n",
    "  if i != 0: plt.yticks([], [])\n",
    "  \n",
    "  plt.hist(a.flatten(), bins=30, range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d765073-7a24-4cce-ad99-4deabb77ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
